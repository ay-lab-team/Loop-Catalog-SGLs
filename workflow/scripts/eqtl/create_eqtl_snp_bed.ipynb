{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd \n",
    "from chromolooper import sgls\n",
    "import re\n",
    "from myvariant import MyVariantInfo\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "from chromolooper import sgls\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "os.chdir('<project-dir>')\n",
    "\n",
    "outdir = 'results/hg38/eqtl/eqtl_catalogue/'\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/mnt/BioHome/jreyna/tmp/ipykernel_1826854/4159143216.py:7: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  gencode_df.loc[:,'gene_id'] = gencode_df.loc[:,'gene_id'].str.replace('\\.[0-9]*', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "old_fn = 'results/hg38/refs/gencode/v30/gencode.v30.annotation.w_genetypes.bed'\n",
    "fn = 'results/hg38/refs/gencode/v30/gencode.v30.annotation.genes_only.bed.gz'\n",
    "gencode_df = pd.read_table(fn, header=None)\n",
    "gencode_df = gencode_df.iloc[:, [0,1,2,5,6,7,8]]\n",
    "gencode_df.columns =['chrom', 'start', 'end', 'strand', 'genename', 'gene_id', 'genetype']\n",
    "# gencode_df = gencode_df.loc[gencode_df.type == 'gene'].drop('type', axis=1)\n",
    "gencode_df.loc[:,'gene_id'] = gencode_df.loc[:,'gene_id'].str.replace('\\.[0-9]*', '', regex=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all eQTL data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_sizes = 'http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pass1 - making usageList (22 chroms): 46 millis\n",
      "pass2 - checking and writing primary data (59350 records, 9 fields): 209 millis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pass1 - making usageList (22 chroms): 61 millis\n",
      "pass2 - checking and writing primary data (63228 records, 9 fields): 219 millis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pass1 - making usageList (22 chroms): 75 millis\n",
      "pass2 - checking and writing primary data (66236 records, 9 fields): 234 millis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pass1 - making usageList (22 chroms): 53 millis\n",
      "pass2 - checking and writing primary data (57544 records, 9 fields): 183 millis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pass1 - making usageList (22 chroms): 51 millis\n",
      "pass2 - checking and writing primary data (65486 records, 9 fields): 216 millis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pass1 - making usageList (22 chroms): 69 millis\n",
      "pass2 - checking and writing primary data (47375 records, 9 fields): 167 millis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# helper function to find snps only\n",
    "def is_snp(variant_id):\n",
    "    var1, var2 = variant_id.split('_')[-2:]\n",
    "    if len(var1) == 1 and len(var2) == 1:\n",
    "        return(True)\n",
    "    return(False)\n",
    "\n",
    "def get_name(sr):\n",
    "    \n",
    "    if type(sr['rsid']) == str:\n",
    "        res = sr['rsid'] + '-' + sr['genename']\n",
    "    else:\n",
    "        res = sr['variant'] + '-' + sr['genename']\n",
    "    return(res)\n",
    "\n",
    "unique_snps = set()\n",
    "credible_set_fns = glob.glob('results/hg38/eqtl/eqtl_catalogue/*.credible_sets.tsv.gz')\n",
    "\n",
    "credible_set_fns = ['results/hg38/eqtl/eqtl_catalogue/QTD000474.credible_sets.tsv.gz',\n",
    "                    'results/hg38/eqtl/eqtl_catalogue/QTD000479.credible_sets.tsv.gz',\n",
    "                    'results/hg38/eqtl/eqtl_catalogue/QTD000489.credible_sets.tsv.gz',\n",
    "                    'results/hg38/eqtl/eqtl_catalogue/QTD000499.credible_sets.tsv.gz',\n",
    "                    'results/hg38/eqtl/eqtl_catalogue/QTD000504.credible_sets.tsv.gz',\n",
    "                    'results/hg38/eqtl/eqtl_catalogue/QTD000509.credible_sets.tsv.gz']\n",
    "                    \n",
    "for fn in credible_set_fns:\n",
    "    tdf = pd.read_table(fn)\n",
    "    tdf = tdf.loc[tdf.variant.apply(is_snp)]\n",
    "    tdf = tdf.merge(gencode_df, on='gene_id')\n",
    "    \n",
    "    ec_dataset_id = os.path.basename(fn).split('.')[0]\n",
    "\n",
    "    \n",
    "    tdf['chrom'] = tdf.variant.apply(lambda x: x.split('_',1)[0])\n",
    "    tdf['end'] = tdf.variant.apply(lambda x: int(x.split('_',2)[1]))\n",
    "    tdf['start'] = tdf['end'] - 1\n",
    "    tdf['name'] = tdf.apply(get_name, axis=1)\n",
    "    tdf['score'] = 1\n",
    "    tdf['strand'] = '+'\n",
    "    tdf['color'] = '117,117,117'\n",
    "    tdf.sort_values(['chrom', 'end', 'start'], inplace=True)\n",
    "\n",
    "    # save the final\n",
    "    rgbpeak_df = tdf[['chrom', 'start', 'end', 'name', 'score', 'strand', 'start', 'end', 'color']]\n",
    "    peak_fn = os.path.join(outdir, '{}.rgbpeak'.format(ec_dataset_id))\n",
    "    rgbpeak_df.to_csv(peak_fn, sep='\\t', index=False, header=False)\n",
    "    \n",
    "    # # compress\n",
    "    # peak_gz_fn = os.path.join(outdir, '{}.rgbpeak.gz'.format(ec_dataset_id))\n",
    "    # cmd = 'bgzip -f {}'.format(peak_fn)\n",
    "    # j = sp.check_output(cmd, shell=True)\n",
    "    # print(j.decode())\n",
    "\n",
    "    \n",
    "    # # tabix\n",
    "    # cmd = 'tabix -f -p bed {}'.format(peak_gz_fn)\n",
    "    # j = sp.check_output(cmd, shell=True)\n",
    "    # print(j.decode())\n",
    "    \n",
    "    bigpeak_fn = os.path.join(outdir, '{}.rgbpeak.bb'.format(ec_dataset_id))\n",
    "    sgls.bed_to_bigbed(peak_fn, bigpeak_fn, genome_sizes, verbose=True)\n",
    "\n",
    "    # need time between runs of bed_to_bigbed\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
