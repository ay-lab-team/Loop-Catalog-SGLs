{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd \n",
    "from chromolooper import sgls\n",
    "from time import sleep\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "os.chdir('/mnt/BioHome/jreyna/jreyna-temp/projects/t1d-loop-catalog/')\n",
    "\n",
    "outdir = 'results/hg38/finemapping/snps/'\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all finemapped snp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add meta information\n",
    "causal_metadata_fn = 'workflow/qscripts/finemap/causal_db/init.gwas_study.causal_db.immune_select_samples.tsv'\n",
    "causal_metadata = pd.read_table(causal_metadata_fn, header=None)\n",
    "\n",
    "causal_metadata_mapper =  causal_metadata.iloc[:, [2, 8, 18]]\n",
    "causal_metadata_mapper.columns = ['mesh_term', 'author', 'filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = glob.glob('results/hg38/finemapping/snps/singles/*_total_credible_set.hg38.txt')\n",
    "\n",
    "all_data = []\n",
    "for i, fn in enumerate(fns):\n",
    "\n",
    "    info = fn.split('/')\n",
    "\n",
    "    causaldb_fn = info[-1].split('_')[0]\n",
    "\n",
    "    if causaldb_fn in causal_metadata_mapper.filename.tolist():\n",
    "\n",
    "        # loading the data\n",
    "        tdf = pd.read_table(fn)\n",
    "        if tdf.shape[0] > 0:\n",
    "            tdf.loc[:, 'causaldb_fn'] = causaldb_fn\n",
    "            all_data.append(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = all_df.merge(causal_metadata_mapper, left_on='causaldb_fn', right_on='filename')\n",
    "\n",
    "all_df.loc[:, 'start'] = all_df.loc[:, 'BP'] - 1\n",
    "all_df.loc[:, 'CHR'] = 'chr' + all_df.loc[:, 'CHR'].astype(str)\n",
    "# all_df.loc[:, 'rsID'] = 'rs' + all_df.loc[:, 'rsID'].astype(str)\n",
    "all_df.loc[:, 'score'] = 1\n",
    "all_df.loc[:, 'strand'] = '+'\n",
    "all_df.loc[:, 'color'] = '117,117,117'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the Washu Track for Single Finemapped Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT258\n",
      "AT280\n",
      "AT452\n",
      "AT454\n",
      "AT548\n",
      "AT551\n",
      "BE151\n",
      "CA104\n",
      "CA265\n",
      "CA266\n",
      "CA391\n",
      "GD08996\n",
      "GD09063\n",
      "GD09159\n",
      "GD09415\n",
      "GD09519\n",
      "GD09657\n",
      "PH378\n"
     ]
    }
   ],
   "source": [
    "filename_grps = all_df.groupby('filename')\n",
    "\n",
    "singles_dir = os.path.join(outdir, 'singles/')\n",
    "os.makedirs(singles_dir, exist_ok=True)\n",
    "\n",
    "for filename, filename_df in filename_grps:\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    # clean the data for washu\n",
    "    filename_df = filename_df[['CHR', 'start', 'BP', 'rsID']].sort_values(['CHR', 'start'])\n",
    "    \n",
    "    # save and compress\n",
    "    out_fn = os.path.join(singles_dir, '{}.finemapped.snps.bed'.format(filename))\n",
    "    filename_df.to_csv(out_fn, sep='\\t', header=False, index=False)\n",
    "    sgls.bgzip(out_fn)\n",
    "    sgls.tabix(out_fn + '.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agg and Make the Washu Track"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bedgraph Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arthritis, Rheumatoid\n",
      "Dermatitis, Atopic\n",
      "Diabetes Mellitus, Type 1\n",
      "Psoriasis\n"
     ]
    }
   ],
   "source": [
    "agg_dir = os.path.join(outdir, 'agg/')\n",
    "os.makedirs(agg_dir, exist_ok=True)\n",
    "\n",
    "for mesh, mesh_df in all_df.groupby('mesh_term'):\n",
    "\n",
    "    print(mesh)\n",
    "\n",
    "    # get and simplify the mesh_name\n",
    "    mesh_name = mesh.replace(',', '').replace(' ', '-').lower()\n",
    "\n",
    "    # clean the data for washu\n",
    "    mesh_df = mesh_df.drop_duplicates(['CHR', 'BP', 'EA', 'NEA'])\n",
    "\n",
    "    # bedgraph format\n",
    "    mesh_df = mesh_df[['CHR', 'start', 'BP', 'score', 'strand', 'rsID']]\n",
    "    mesh_df = mesh_df.sort_values(['CHR', 'start'])\n",
    "\n",
    "    # qbed format\n",
    "    #mesh_df = mesh_df[['CHR', 'start', 'BP', 'score', 'strand', 'rsID', 'mesh_term']]\n",
    "    \n",
    "    # save and compress\n",
    "    out_fn = os.path.join(agg_dir, '{}.finemapped.snps.bedgraph'.format(mesh_name))\n",
    "    mesh_df.to_csv(out_fn, sep='\\t', header=False, index=False)\n",
    "    sgls.bgzip(out_fn)\n",
    "    sgls.tabix(out_fn + '.gz', type='bed')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rgbpeak Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genome_sizes = '/mnt/BioHome/jreyna/hichip-db-loop-calling/results/refs/reference_genomes/RefGenome/chrsize/hg38.chrom.sizes'\n",
    "genome_sizes = 'http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arthritis, Rheumatoid\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pass1 - making usageList (16 chroms): 34 millis\n",
      "pass2 - checking and writing primary data (1043 records, 9 fields): 7 millis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dermatitis, Atopic\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pass1 - making usageList (16 chroms): 32 millis\n",
      "pass2 - checking and writing primary data (674 records, 9 fields): 6 millis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes Mellitus, Type 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pass1 - making usageList (22 chroms): 34 millis\n",
      "pass2 - checking and writing primary data (6155 records, 9 fields): 21 millis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psoriasis\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pass1 - making usageList (20 chroms): 33 millis\n",
      "pass2 - checking and writing primary data (559 records, 9 fields): 7 millis\n"
     ]
    }
   ],
   "source": [
    "agg_dir = os.path.join(outdir, 'agg/')\n",
    "os.makedirs(agg_dir, exist_ok=True)\n",
    "\n",
    "mesh_grps = all_df.groupby('mesh_term')\n",
    "\n",
    "for mesh, mesh_df in mesh_grps:\n",
    "\n",
    "    print(mesh)\n",
    "\n",
    "    # get and simplify the mesh_name\n",
    "    mesh_name = mesh.replace(',', '').replace(' ', '-').lower()\n",
    "\n",
    "    # clean the data for washu\n",
    "    mesh_df = mesh_df.drop_duplicates(['CHR', 'BP', 'EA', 'NEA'])\n",
    "\n",
    "    # rbgpeak format\n",
    "    # chrom, start, end, peak_id, score, strand, thick_start, thick_end, RGB value\n",
    "    mesh_df = mesh_df[['CHR', 'start', 'BP', 'rsID', 'score', 'strand', 'start', 'BP', 'color']]\n",
    "    mesh_df.columns = ['chrom', 'start', 'end', 'peak_id', 'score', 'strand', 'thick_start', 'thick_end', 'RGB']\n",
    "    mesh_df = mesh_df.sort_values(['chrom', 'start'])\n",
    "    \n",
    "    # save and compress\n",
    "    peak_fn = os.path.join(agg_dir, '{}.finemapped.snps.rgbpeak'.format(mesh_name))\n",
    "    mesh_df.to_csv(peak_fn, sep='\\t', header=False, index=False)\n",
    "\n",
    "    bigpeak_fn = os.path.join(agg_dir, '{}.finemapped.snps.rgbpeak.bb'.format(mesh_name))\n",
    "    sgls.bed_to_bigbed(peak_fn, bigpeak_fn, genome_sizes, verbose=True)\n",
    "\n",
    "    # need time between runs of bed_to_bigbed\n",
    "    sleep(2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(hichip-db)",
   "language": "python",
   "name": "hichip-db"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
