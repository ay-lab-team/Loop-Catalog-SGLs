#########################################################################################
# Rules to analyze ALL eQTLs (no FDR filtering)
#########################################################################################

# Liftover the extra SNP information which was generated by Sourya using DICE data
# Some of the values here are parameters for each SNP such as allele frequency but also
# these files contain RSID, ref, alt, etc information.
rule liftover_snp_info_grch37_to_grch38: # (Status: running)
    input:
        txt = 'results/refs/coloc_snps_meta/grch37/SNPInfo/snpinfo_chr{chr_num}.txt',
        chain = rules.download_chain_file_hg19tohg38.output
    output:
        txt = 'results/refs/coloc_snps_meta/grch38/SNPInfo/snpinfo_chr{chr_num}.txt'
    log: 
        'results/refs/coloc_snps_meta/grch38/SNPInfo/logs/snpinfo_chr{chr_num}.log'
    shell:
        r"""
            # prepare the input liftover file
            echo "# prepare the input liftover file" > {log}
            liftover_input="{input.txt}.liftover.input.bed"
            cat {input.txt} | \
              sed '1d' | \
              awk 'BEGIN{{OFS="\t"}}; {{print $1,($2 - 1),$2,$3,$4,$5,$6,$7,$8,$9}}' > \
              $liftover_input 2>> {log}

            # perform the liftover
            echo "# perform the liftover_snp_info" >> {log}
            lifted="{input.txt}.lifted.bed"
            unmapped="{input.txt}.unmapped.txt"
            {config[liftover]} -bedPlus=3 \
                             -tab $liftover_input \
                             {input.chain} \
                             $lifted \
                             $unmapped 2>> {log}

            # convert back to the regular format
            echo "# convert back to the regular format" >> {log}
            interm="{input.txt}.interm.txt"
            cut -f 2 --complement --output-delimiter " " $lifted > $interm 2>> {log}

            # fix the third column and complete the preprocessing
            echo "# fix the third column and complete the preprocessing" >> {log}
            head -n 1 {input.txt} > {output.txt}
            cat $interm | \
                awk '{{chrom=gensub(/chr/, "", 1, $1); print $1, $2, (chrom":"$2":"$5":"$6), $4, $5, $6, $7, $8, $9}}' >> \
                {output.txt} 2>> {log}
    
            # remove remaining files
            echo "# remove remaining files" >> {log}
            echo $liftover_input $lifted $unmapped
            #rm $liftover_input $lifted $unmapped > {log}

        """

# This file doesn not contain a chr and position field, rather it has a 
# sid filed form which you can generated these two.
rule calculate_dist_col: # (Status: running)
    input:
        gencode = 'results/refs/gencode/v30/gencode.v30.annotation.bed',
        eqtl = 'results/main/eqtl/{eqtl_source}/ge/{eqtl_source}_ge_{ge_source}.all.tsv.gz'
    output:
        'results/main/eqtl/{eqtl_source}/ge/{eqtl_source}_ge_{ge_source}.all.dist.txt'
    log: 
        'results/main/eqtl/logs/calculate_dist_col.{eqtl_source}.{ge_source}.log'
    params:
        pos = 3,
        gene_id = 17
    resources:
        mem_mb = 16000,
        nodes = 1,
        ppn = 1,
    shell:
        r'''
            /mnt/BioHome/jreyna/software/anaconda3/envs/hic_tls/bin/python \
                    workflow/scripts/eqtl/Calculate_Dist_Col.py \
                        --header \
                        {input.gencode} \
                        {input.eqtl} \
                        {params.pos} \
                        {params.gene_id} \
                        {output} >> {log} 2>&1
        '''


# This file doesn not contain a chr and position field, rather it has a 
# sid field form which you can generated these two.
rule calculate_fdr_col: # (Status: running)
    input:
        eqtl = 'results/main/eqtl/{eqtl_source}/ge/{eqtl_source}_ge_{ge_source}.all.tsv.gz'
    output:
        'results/main/eqtl/{eqtl_source}/ge/{eqtl_source}_ge_{ge_source}.all.fdr.txt'
    log: 
        'results/main/eqtl/logs/calculate_fdr_col.{eqtl_source}.{ge_source}.log'
    params:
        pval = 9
    resources:
        mem_mb = 24000,
        nodes = 1,
        ppn = 1,
    shell:
        r'''
            /mnt/BioHome/jreyna/software/anaconda3/envs/hic_tls/bin/python \
                        workflow/scripts/eqtl/Calc_FDR_Col.py \
                        --in-header \
                        --out-header \
                        {input} \
                        {output} \
                        9 >> {log} 2>&1
        '''


# After running calculate_dist_col this rule will add the dist column to the tsv.gz data
rule add_missing_cols: #(Status: running)
    input:
        eqtl = 'results/main/eqtl/{eqtl_source}/ge/{eqtl_source}_ge_{ge_source}.all.tsv.gz',
        dist = rules.calculate_dist_col.output,
        fdr = rules.calculate_fdr_col.output
    params:
        interm1 = 'results/main/eqtl/{eqtl_source}/ge/{eqtl_source}_ge_{ge_source}.all.temp.tsv',
        interm2 = 'results/main/eqtl/{eqtl_source}/ge/{eqtl_source}_ge_{ge_source}.all.dist.fdr.tsv'
    output:
        'results/main/eqtl/{eqtl_source}/ge/{eqtl_source}_ge_{ge_source}.all.dist.fdr.tsv.gz'
    log: 
        'results/main/eqtl/logs/add_missing_cols.{eqtl_source}.{ge_source}.log'
    resources:
        mem_mb = 32000,
        nodes = 1,
        ppn = 1,
    shell:
        r'''
            echo "running gzip" >> {log} 2>&1
            gzip -cd {input.eqtl} > {params.interm1} 2>> {log}

            echo "running paste" >> {log} 2>&1
            paste {params.interm1} {input.dist} {input.fdr} | tr -d '\r' > {params.interm2} 2>> {log}

            echo "running bgzip" >> {log} 2>&1
            {config[bgzip]} {params.interm2} 2>> {log}

            echo "running rm" >> {log} 2>&1
            rm {params.interm1} 2>> {log}
        '''


# This file doesn not contain a chr and position field, rather it has a 
# sid filed form which you can generated these two.
rule processing_eqtl_catalog_with_complete_fields: # (status: running)
    input:
        rules.add_missing_cols.output
    output:
        'results/main/eqtl/{eqtl_source}/ge/{eqtl_source}_ge_{ge_source}.all.dist.fdr.input.tsv.gz'
    params:
        interm='results/main/eqtl/{eqtl_source}/ge/{eqtl_source}_ge_{ge_source}.all.dist.fdr.input.tsv'
    log: 
        'results/main/coloc/Results/eQTL_Catalogue/logs/parse_eqtl_catalog_with_complete_fields.{eqtl_source}.{ge_source}.log'
    resources:
        mem_mb = 12000,
        nodes = 1,
        ppn = 1,
    shell:
        r'''
            echo "zcat + sed + awk processing" >> {log}
            zcat {input} | \
                 sed '1d' | \
                 awk 'BEGIN{{OFS="	"}}; {{print "chr"$2, $3, $17, $20, $10, $9, $21}}' > \
                 {params.interm} 2>> {log}
            {config[bgzip]} {params.interm} 2>> {log}
        '''


# run colocalization with GWAS filtered for FDR < 0.05 and 
# eQTL with no filter. This is the main way we are using to run
# the colocalization analysis. The main motivation being that we
# need to select regions however, if we include al eQTL we would 
# be analyzing even regions without significant GWAS SNPs. 
rule run_colocalization_eqtl_catalog: #(Status: running)
    input:
        snp_info_dir = 'results/refs/coloc_snps_meta/grch38/SNPInfo/',
        gwas = rules.liftover_grch37_to_38_gwas_summary_stats.output,
        eqtl = rules.processing_eqtl_catalog_with_complete_fields.output
    output:
        final = protected('results/main/coloc/Results/eQTL_Catalogue/{gwas_source}/{eqtl_source}/{ge_source}/FINAL_Summary_Coloc_Gene_SNP_Pairs.bed')
    log: 
        'results/main/coloc/Results/eQTL_Catalogue/logs/run_colocalization_eqtl_catalog.{gwas_source}.{eqtl_source}.{ge_source}.log'
    params:
        outdir = 'results/main/coloc/Results/eQTL_Catalogue/{gwas_source}/{eqtl_source}/{ge_source}/',
        chr = 1,
        pos = 2,
        gene_name = 3,
        dist = 4,
        slope = 5,
        pvalue = 6,
        fdr = 7,
        header = 'FALSE'
    resources:
        mem_mb = 48000,
        nodes = 1,
        ppn = 1,
    shell:
        r"""
            # make the log directory
            mkdir -p $(dirname {log})

            # set the tempdir 
            TMPDIR=/scratch

            # add the corresponding R for colocalization analyses
            PATH=/mnt/BioApps/R/3.6.1/bin/:$PATH

            # run colocalization command
            # omitting --eqtl-FDR {params.fdr} since eQTL Catalog doesn't have FDR/qvalue
            # Omitting --eqtl-header {params.header} since header was removed previously
            #Rscript scripts/coloc/Colocalization_Analysis_GWAS_Script_Generalized.R \
            Rscript workflow/scripts/coloc/Colocalization_Analysis_GWAS_Script_Generalized.Sourya_Mod.20220221.R \
                                --eqtl-chr {params.chr} \
                                --eqtl-pos {params.pos} \
                                --eqtl-geneName {params.gene_name} \
                                --eqtl-dist {params.dist} \
                                --eqtl-slope {params.slope} \
                                --eqtl-pvalue {params.pvalue} \
                                --eqtl-FDR {params.fdr} \
                                {input.snp_info_dir} \
                                {input.gwas} \
                                {input.eqtl} \
                                {params.outdir} >> {log} 2>&1
        """


# liftover the colocalization SNP to GRCh37
rule liftover_colocalization_hg38_to_hg19: #(Status: developing)
    input:
        rules.run_colocalization_eqtl_catalog.output.final 
    output:
        final = protected('results/main/GRCh37/coloc/Results/eQTL_Catalogue/{gwas_source}/{eqtl_source}/{ge_source}/FINAL_Summary_Coloc_Gene_SNP_Pairs.bed')
    log: 
        'results/main/GRCh37/coloc/Results/eQTL_Catalogue/logs/run_colocalization_eqtl_catalog.{gwas_source}.{eqtl_source}.{ge_source}.log'
    params:
        chr = 1,
        pos = 2,
        sep = '\t',
        header = 'TRUE'
    shell:
        r"""
            python workflow/scripts/utilities/general_liftover.py \
                    -i {input} \
                    -o {output} \
                    --chr-col {params.chr} \
                    --pos-col {params.pos} \
                    --header \
                    --sep "{params.sep}" > {log} 2>&1
        """


# find LD pairs for the colocalization SNPs
rule find_ldpairs_for_coloc_snps:
    input:
        snp_file = rules.liftover_colocalization_hg38_to_hg19.output.final,
        onekg_dir = '/mnt/BioAdHoc/Groups/vd-vijay/Ariel/R24_new/LD-snps-1000G/DupsRemoved/',
        population_dir = '/mnt/BioAdHoc/Groups/vd-vijay/Ariel/R24_new/LD-snps/lists-pops/',
        snpinfo_dir = '/mnt/BioAdHoc/Groups/vd-vijay/sourya/Projects/2020_IQTL_HiChIP/Data/SNPInfo/SNPInfo_merged_tables/'
    params:
        workdir = 'results/main/GRCh37/coloc/eQTL_Catalogue/{gwas_source}/{eqtl_source}/{ge_source}/ldpairs/',
        chr_col = 1,
        pos_col = 2
    resources:
        mem_mb = 20000
    output:
        ld = 'results/main/GRCh37/coloc/eQTL_Catalogue/{gwas_source}/{eqtl_source}/{ge_source}/ldpairs/coloc_ld_snps.txt'
    log:
        'results/main/GRCh37/coloc/eQTL_Catalogue/{gwas_source}/{eqtl_source}/{ge_source}/ldpairs/coloc_ld_snps.log'
    shell:
        r"""
            Rscript workflow/scripts/ldpairs/ldpair_with_plink.R \
                        --snp-file {input.snp_file} \
                        --onekg-dir {input.onekg_dir}/ \
                        --population-dir {input.population_dir}/ \
                        --snpinfo-dir {input.snpinfo_dir}/ \
                        --header \
                        --chr-prefix \
                        --chr-col {params.chr_col} \
                        --pos-col {params.pos_col} \
                        --workdir {params.workdir}/ > {log} 2>&1
            old_fn="{params.workdir}/Out_Merge_LD.txt"
            mv $old_fn {output} > {log} 2>&1

        """


#########################################################################################
# Rules to analyze significant eQTLs (yes FDR filtering)
#########################################################################################

# Count the number of eqtls before filtering on FDR
rule calculate_number_of_eqtls_pre_filtering: # (Status: running)
    input:
        eqtl = 'results/main/eqtl/{eqtl_source}/ge/{eqtl_source}_ge_{ge_source}.all.tsv.gz'
    output:
        'results/main/eqtl/{eqtl_source}/ge/{eqtl_source}_ge_{ge_source}.all.prefilter.num_eqtls.txt'
    log: 
        'results/main/eqtl/logs/calculate_number_of_eqtls_pre_filtering.{eqtl_source}.{ge_source}.log'
    resources:
        mem_mb = 4000,
        nodes = 1,
        ppn = 1,
    shell:
        r'''
            zcat {input} | wc -l  > {output} 2> {log}
        '''
